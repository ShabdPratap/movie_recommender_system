# -*- coding: utf-8 -*-
"""MovieRecommenderSys.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wQhWvKvRpouA3NTzRuoHbwIGX8z3bSe_
"""

import pandas as pd
import numpy as np

Credits="/content/drive/MyDrive/tmdb_5000_credits.csv"
Movies="/content/drive/MyDrive/tmdb_5000_movies.csv"


credits=pd.read_csv(Credits)##Reading the both credits and movies file
movies=pd.read_csv(Movies)

movies.head(1)

credits.head(1)

movies=movies.merge(credits, on="title") ##merging both the tables reassigning the movies data as Shape of credit table is 23

movies.head(1)

###Remove the columns which are not helpful in the discussion###
##TO CREATE TAGS FOR EVERY MOVIE is my workflow

movies.info()

#features to take
#genres
#id
#keywords
#title
#overview
#cast
#crew

movies=movies[["genres", 'id', 'keywords', 'title', 'overview', 'cast','crew']]

movies.head(1)

#Data preprocessing is done before doin anything
movies.isnull().sum()

movies.dropna(inplace=True) ##for dropping the null values 3 values present in overview

#checking the duplicate values
movies.duplicated().sum()

#make the right format of the columns of different features
movies.iloc[0].genres #its a weird format

#converting the dictionary format to the LIST format
#['action','adventure','fantasy', 'Science Fiction']

#WE CAN CREATE A HELPER FUNCTION

def convert(obj):
  L=[]
  # for i in obj:
  for i in ast.literal_eval(obj):   #to convert the string of list to list
    L.append(i['name'])
  return L

#####WE HAVE TO CONVERT A STRING OF LIST TO THE LIST WITH THE HELP OF AST MODULE
import ast
ast.literal_eval('[{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"}, {"id": 878, "name": "Science Fiction"}]')

##Use Apply function to convert the all geners into the list

movies['genres'].apply(convert)

##Adding this form of genere to the existing genre columns
movies['genres']=movies['genres'].apply(convert)

movies.head(1)

#we want only 3 values for cast and crew to need to use new helper function

def convert3(obj):
  L=[]
  count=0
  for i in ast.literal_eval(obj):
    if count!=3:
      L.append(i['name'])
      count+=1;
    else:
      break
  return L;

##DO THE SAME THING FOR ALL COLUMNS ALSO
movies['keywords']=movies['keywords'].apply(convert)

movies['cast']=movies['cast'].apply(convert3)

movies.head(1)

movies['crew'][0]

##MAKING A FUNCITON FOR SEPERATING THE DIRECTORS FROM THE CREW

def convert1(obj):
  L=[]
  for i in ast.literal_eval(obj):
    if i['job']=='Director':
      L.append(i['name'])
      break
  return L

movies['crew']=movies['crew'].apply(convert1)

movies.head(5)

movies['overview'][0]

#converting this overview string into list
movies['overview']=movies['overview'].apply(lambda x:x.split())

##NOW OUR TASK TO CONCATINATE THE ALL THE LIST
#BEFORE THAT ONE PROBLEM ARISE

"""# Convert 'James cameron' to 'Jamescameron' cause james and cameron aise alag Tag ban jayega agr data mein james mandice bhi hai to model get confused.

"""

#to get the non spaced values
movies['genres']=movies['genres'].apply(lambda x:[i.replace(" ","") for i in x])
movies['keywords']=movies['keywords'].apply(lambda x:[i.replace(" ","") for i in x])
movies['cast']=movies['cast'].apply(lambda x:[i.replace(" ","") for i in x])
movies['crew']=movies['crew'].apply(lambda x:[i.replace(" ","") for i in x])

movies.head(5)

movies['tags']=movies['overview'] + movies['keywords'] + movies['cast'] + movies['crew'] + movies['genres']

newdf=movies[['id', 'title', 'tags']]

newdf.head(5)

#convert the list into string
newdf['tags']=newdf['tags'].apply(lambda x:" ".join(x))

newdf['tags'][0]

newdf['tags']=newdf['tags'].apply(lambda x:[i.lower() for i in x] if isinstance(x, list) else str(x).lower())

newdf.head(5)

#MOST IMPORTANT, USE VECTORISATION TECHNIQUE TO CONVERT THE WHOLE TEXT INTO VECTOR

from sklearn.feature_extraction.text import CountVectorizer
cv=CountVectorizer(max_features=5000, stop_words='english')

vector=cv.fit_transform(newdf['tags']).toarray();

vector[0]

#now have to steming to remove duplicate featurs
!pip install nltk

from nltk.stem.porter import PorterStemmer
ps=PorterStemmer() #creating the object of this library

#making the helper function
def stem(text):
  L=[]
  for i in text.split():
    L.append(ps.stem(i))
  return " ".join(L)

newdf['tags']=newdf['tags'].apply(stem)

from sklearn.metrics.pairwise import cosine_similarity #values comes to 0-1
similarity=cosine_similarity(vector) #calculating all the distances of movies 4806 distances

similarity.shape

similarity[0] #calculate distance of 1st movie to all the other movies
#diagonal will always be one in this matix

newdf[newdf['title']=='Avatar'].index[0] ##fetching the index of each movie

# sorted(list(enumerate(similarity[0])),reverse=True) #here last movie comes first
sorted(list(enumerate(similarity[0])),reverse=True, key=lambda x:x[1])[1:6] #have to sort second number basis

def recommend(movie):
  movie_index=newdf[newdf['title']=='Avatar'].index[0]

  distances=similarity[movie_index] #similarity matrix index

  movies_list=sorted(list(enumerate(distances)),reverse=True, key=lambda x:x[1])[1:6]

  for i in movies_list:
    # print(i[0])
    print(newdf.iloc[i[0]].title) #fetching the movie title from newdf dataframe

recommend('Avatar')

###lets convert into its website

import pickle

pickle.dump(newdf, open('movies.pkl','wb')) #wb is wide binary mode

pickle.dump(newdf.to_dict(), open('movies_dict.pkl','wb'))

pickle.dump(similarity, open('similarity.pkl','wb'))

